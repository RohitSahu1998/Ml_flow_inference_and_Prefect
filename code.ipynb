{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/29 00:45:33 INFO mlflow.tracking.fluent: Experiment with name 'Review_sentiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///e:/Internship_2024/Backend_data/ml_flow/mlruns/695524463574134291', creation_time=1711653333152, experiment_id='695524463574134291', last_update_time=1711653333152, lifecycle_stage='active', name='Review_sentiment', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"Review_sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"E:\\Internship_2024\\Backend_data\\ml_flow\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3     Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                          NaN     147.0        24.0  Apr 2016   \n",
       "\n",
       "                                         Review text  Ratings  \n",
       "0  Nice product, good quality, but price is now r...        4  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3  Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...        1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df[['Review text',\"Ratings\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review text    0\n",
       "Ratings        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=new_df['Review text']\n",
    "y=new_df['Ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6382,) (2128,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/29 10:37:32 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "CPU times: total: 22min 6s\n",
      "Wall time: 18min 35s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define pipeline steps\n",
    "pipe_1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "# Observe the Key Value Pair format\n",
    "parameter_grid_1 = [\n",
    "    {\n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],  # Adjust ngram_range as needed\n",
    "        'tfidf__max_features': [1000, 2000, 3000],  # Adjust max_features as needed\n",
    "        'classifier__n_neighbors': [i for i in range(3, 21, 2)],\n",
    "        'classifier__p': [1, 2, 3]\n",
    "    }\n",
    "]\n",
    "clf = GridSearchCV(\n",
    "    estimator=pipe_1, \n",
    "    param_grid=parameter_grid_1, \n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Initialize the auto logger\n",
    "# max_tuning_runs=None will make sure that all the runs are recorded.\n",
    "# By default top 5 runs will be recorded for each experiment\n",
    "mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    %time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'knn' : Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    ", \n",
    "    'svc' : Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ]),\n",
    "    'logistic_regression': Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ]),\n",
    "    'random_forest': Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ]),\n",
    "    'decision_tree': Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'naive_bayes':Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', GaussianNB())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Define parameter grid for each algorithm\n",
    "\n",
    "param_grids = {\n",
    "    'knn': [\n",
    "        {\n",
    "            \n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],  # Adjust ngram_range as needed\n",
    "        'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__n_neighbors' : [i for i in range(3, 21, 2)], \n",
    "            'classifier__p' : [1, 2, 3]\n",
    "        }\n",
    "    ],\n",
    "    'svc': [\n",
    "        {\n",
    "            \n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],  # Adjust ngram_range as needed\n",
    "        'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__kernel' : ['rbf'], \n",
    "            'classifier__C' : [0.1, 0.01, 1, 10, 100]\n",
    "        }, \n",
    "        {\n",
    "            \n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],  # Adjust ngram_range as needed\n",
    "        'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__kernel' : ['poly'], \n",
    "            'classifier__degree' : [2, 3, 4, 5], \n",
    "            'classifier__C' : [0.1, 0.01, 1, 10, 100]\n",
    "        }, \n",
    "        {\n",
    "            \n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],  # Adjust ngram_range as needed\n",
    "        'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__kernel' : ['linear'], \n",
    "            'classifier__C' : [0.1, 0.01, 1, 10, 100]\n",
    "        }\n",
    "    ],\n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            \n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],  # Adjust ngram_range as needed\n",
    "        'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['l2']\n",
    "        }, \n",
    "        {\n",
    "            \n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],  # Adjust ngram_range as needed\n",
    "        'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['l1'], \n",
    "            'classifier__solver': ['liblinear']\n",
    "        }, \n",
    "        {\n",
    "           \n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],  # Adjust ngram_range as needed\n",
    "        'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['elasticnet'], \n",
    "            'classifier__l1_ratio': [0.4, 0.5, 0.6],\n",
    "            'classifier__solver': ['saga']\n",
    "        }\n",
    "    ],\n",
    "    'random_forest': [\n",
    "        {\n",
    "            \n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],  # Adjust ngram_range as needed\n",
    "        'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__n_estimators': [50, 100, 200]\n",
    "        }\n",
    "    ],\n",
    "    'decision_tree': [\n",
    "        {\n",
    "           \n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],  # Adjust ngram_range as needed\n",
    "        'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__max_depth': [None, 5, 10]\n",
    "        }\n",
    "    ],\n",
    "    'naive_bayes': [\n",
    "        {\n",
    "           \n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],  # Adjust ngram_range as needed\n",
    "        'tfidf__max_features': [1000, 2000, 3000],\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** knn **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/29 11:22:02 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "CPU times: total: 21min 55s\n",
      "Wall time: 17min 46s\n",
      "Train Score:  0.6486982126506334\n",
      "Test Score:  0.6339285714285714\n",
      "\n",
      "********** svc **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/29 11:39:45 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "CPU times: total: 1h 35min 4s\n",
      "Wall time: 1h 40min 53s\n",
      "Train Score:  0.6659378735918577\n",
      "Test Score:  0.6602443609022557\n",
      "\n",
      "********** logistic_regression **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/29 13:21:15 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "CPU times: total: 36min 22s\n",
      "Wall time: 39min 16s\n",
      "Train Score:  0.6637420433372692\n",
      "Test Score:  0.6578947368421053\n",
      "\n",
      "********** random_forest **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/29 14:01:46 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "CPU times: total: 22min 58s\n",
      "Wall time: 32min 10s\n",
      "Train Score:  0.657159584940213\n",
      "Test Score:  0.6484962406015038\n",
      "\n",
      "********** decision_tree **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/29 14:34:03 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "CPU times: total: 2min 3s\n",
      "Wall time: 2min 52s\n",
      "Train Score:  0.6480714988842875\n",
      "Test Score:  0.6358082706766918\n",
      "\n",
      "********** naive_bayes **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/29 14:36:57 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 30 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 578, in safe_patch_function\n    patch_function(call_original, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 251, in patch_with_managed_run\n    result = patch_function(original, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 1659, in patched_fit\n    return original(self, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 559, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 494, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 556, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 578, in safe_patch_function\n    patch_function(call_original, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 251, in patch_with_managed_run\n    result = patch_function(original, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 1659, in patched_fit\n    return original(self, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 559, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 494, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 556, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 263, in fit\n    return self._partial_fit(\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 423, in _partial_fit\n    X, y = self._validate_data(X, y, reset=first_call)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1263, in check_X_y\n    X = check_array(\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 963, in check_array\n    array = _ensure_sparse_format(\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 595, in _ensure_sparse_format\n    raise TypeError(\nTypeError: Sparse data was passed for X, but dense data is required. Use '.toarray()' to convert to a dense numpy array.\n\n--------------------------------------------------------------------------------\n29 fits failed with the following error:\nTraceback (most recent call last):\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 458, in safe_patch_function\n    return original(*args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 458, in safe_patch_function\n    return original(*args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 263, in fit\n    return self._partial_fit(\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 423, in _partial_fit\n    X, y = self._validate_data(X, y, reset=first_call)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1263, in check_X_y\n    X = check_array(\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 963, in check_array\n    array = _ensure_sparse_format(\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 595, in _ensure_sparse_format\n    raise TypeError(\nTypeError: Sparse data was passed for X, but dense data is required. Use '.toarray()' to convert to a dense numpy array.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[1;32me:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:578\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    576\u001b[0m     patch_function\u001b[38;5;241m.\u001b[39mcall(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 578\u001b[0m     patch_function(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    580\u001b[0m session\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m try_log_autologging_event(\n\u001b[0;32m    583\u001b[0m     AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_patch_function_success,\n\u001b[0;32m    584\u001b[0m     session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m     kwargs,\n\u001b[0;32m    589\u001b[0m )\n",
      "File \u001b[1;32me:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:251\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001b[1;34m(original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m     managed_run \u001b[38;5;241m=\u001b[39m create_managed_run()\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     result \u001b[38;5;241m=\u001b[39m patch_function(original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m managed_run:\n",
      "File \u001b[1;32me:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1652\u001b[0m, in \u001b[0;36m_autolog.<locals>.patched_fit\u001b[1;34m(fit_impl, allow_children_patch, original, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mshould_log():\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;66;03m# In `fit_mlflow` call, it will also call metric API for computing training metrics\u001b[39;00m\n\u001b[0;32m   1650\u001b[0m     \u001b[38;5;66;03m# so we need temporarily disable the post_training_metrics patching.\u001b[39;00m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _AUTOLOGGING_METRICS_MANAGER\u001b[38;5;241m.\u001b[39mdisable_log_post_training_metrics():\n\u001b[1;32m-> 1652\u001b[0m         result \u001b[38;5;241m=\u001b[39m fit_impl(original, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_log_post_training_metrics:\n\u001b[0;32m   1654\u001b[0m         _AUTOLOGGING_METRICS_MANAGER\u001b[38;5;241m.\u001b[39mregister_model(\n\u001b[0;32m   1655\u001b[0m             \u001b[38;5;28mself\u001b[39m, mlflow\u001b[38;5;241m.\u001b[39mactive_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m   1656\u001b[0m         )\n",
      "File \u001b[1;32me:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1427\u001b[0m, in \u001b[0;36m_autolog.<locals>.fit_mlflow\u001b[1;34m(original, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1425\u001b[0m _log_pretraining_metadata(autologging_client, \u001b[38;5;28mself\u001b[39m, X, y_true)\n\u001b[0;32m   1426\u001b[0m params_logging_future \u001b[38;5;241m=\u001b[39m autologging_client\u001b[38;5;241m.\u001b[39mflush(synchronous\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1427\u001b[0m fit_output \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1428\u001b[0m _log_posttraining_metadata(autologging_client, \u001b[38;5;28mself\u001b[39m, X, y_true, sample_weight)\n\u001b[0;32m   1429\u001b[0m autologging_client\u001b[38;5;241m.\u001b[39mflush(synchronous\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32me:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:559\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m         original_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39m_og_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_og_kwargs)\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[1;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:494\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[1;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    486\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    487\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_start,\n\u001b[0;32m    488\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m         og_kwargs,\n\u001b[0;32m    493\u001b[0m     )\n\u001b[1;32m--> 494\u001b[0m     original_fn_result \u001b[38;5;241m=\u001b[39m original_fn(\u001b[38;5;241m*\u001b[39mog_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mog_kwargs)\n\u001b[0;32m    496\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    497\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_success,\n\u001b[0;32m    498\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    502\u001b[0m         og_kwargs,\n\u001b[0;32m    503\u001b[0m     )\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[1;32me:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:556\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[1;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[0;32m    553\u001b[0m     disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    554\u001b[0m     reroute_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    555\u001b[0m ):\n\u001b[1;32m--> 556\u001b[0m     original_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39m_og_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_og_kwargs)\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "File \u001b[1;32me:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32me:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    945\u001b[0m     )\n\u001b[1;32m--> 947\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32me:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m     )\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 30 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 578, in safe_patch_function\n    patch_function(call_original, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 251, in patch_with_managed_run\n    result = patch_function(original, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 1659, in patched_fit\n    return original(self, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 559, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 494, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 556, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 578, in safe_patch_function\n    patch_function(call_original, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 251, in patch_with_managed_run\n    result = patch_function(original, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 1659, in patched_fit\n    return original(self, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 559, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 494, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 556, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 263, in fit\n    return self._partial_fit(\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 423, in _partial_fit\n    X, y = self._validate_data(X, y, reset=first_call)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1263, in check_X_y\n    X = check_array(\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 963, in check_array\n    array = _ensure_sparse_format(\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 595, in _ensure_sparse_format\n    raise TypeError(\nTypeError: Sparse data was passed for X, but dense data is required. Use '.toarray()' to convert to a dense numpy array.\n\n--------------------------------------------------------------------------------\n29 fits failed with the following error:\nTraceback (most recent call last):\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 458, in safe_patch_function\n    return original(*args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 458, in safe_patch_function\n    return original(*args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 263, in fit\n    return self._partial_fit(\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 423, in _partial_fit\n    X, y = self._validate_data(X, y, reset=first_call)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1263, in check_X_y\n    X = check_array(\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 963, in check_array\n    array = _ensure_sparse_format(\n  File \"e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 595, in _ensure_sparse_format\n    raise TypeError(\nTypeError: Sparse data was passed for X, but dense data is required. Use '.toarray()' to convert to a dense numpy array.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run() \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[0;32m     17\u001b[0m     get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrid_search.fit(X_train, y_train)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Score: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_score_\u001b[49m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Score: \u001b[39m\u001b[38;5;124m'\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mscore(X_test, y_test))\n\u001b[0;32m     22\u001b[0m best_models[algo] \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "\n",
    "# Run the Pipeline\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    \n",
    "    mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        %time grid_search.fit(X_train, y_train)\n",
    "        \n",
    "    print('Train Score: ', grid_search.best_score_)\n",
    "    print('Test Score: ', grid_search.score(X_test, y_test))\n",
    "    \n",
    "    best_models[algo] = grid_search.best_estimator_\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefect code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_inputs_output(data, inputs, output):\n",
    "    \"\"\"\n",
    "    Split features and target variables.\n",
    "    \"\"\"\n",
    "    X=new_df['Review text']\n",
    "    y=new_df['Ratings']\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Rescale the data.\n",
    "    \"\"\"\n",
    "    scaler = TfidfVectorizer()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train_scaled, y_train, hyperparameters):\n",
    "    \"\"\"\n",
    "    Training the machine learning model.\n",
    "    \"\"\"\n",
    "    clf = KNeighborsClassifier(**hyperparameters)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train_scaled, y_train, hyperparameters):\n",
    "    \"\"\"\n",
    "    Training the machine learning model.\n",
    "    \"\"\"\n",
    "    clf = KNeighborsClassifier(**hyperparameters)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Compute accuracy scores\n",
    "    train_score = accuracy_score(y_train, y_train_pred)\n",
    "    test_score = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    return train_score, test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"New_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workflow(data_path):\n",
    "    DATA_PATH = data_path\n",
    "    INPUTS = ['Review text']\n",
    "    OUTPUT = ['Ratings']\n",
    "    HYPERPARAMETERS = {'n_neighbors': 3, 'p': 2}\n",
    "    \n",
    "    # Load data\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Identify Inputs and Output\n",
    "    X, y = split_inputs_output(data, INPUTS, OUTPUT)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # Preprocess the data\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Build a model\n",
    "    model = train_model(X_train_scaled, y_train, HYPERPARAMETERS)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_score, test_score = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    \n",
    "    print(\"Train Score:\", train_score)\n",
    "    print(\"Test Score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/29 16:30:38 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ea826cbf93a748db82ab4c75ab0bd693', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/03/29 16:30:38 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.6886555938577249\n",
      "Test Score: 0.6151315789473685\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    workflow(data_path=r\"E:\\Internship_2024\\Backend_data\\ml_flow\\New_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prefect\n",
      "  Downloading prefect-2.16.7-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 734.2 kB/s eta 0:00:00\n",
      "Collecting rich<14.0,>=11.0\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "     ------------------------------------ 240.7/240.7 KB 984.8 kB/s eta 0:00:00\n",
      "Collecting rfc3339-validator<0.2.0,>=0.1.4\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Collecting websockets<13.0,>=10.4\n",
      "  Downloading websockets-12.0-cp310-cp310-win_amd64.whl (124 kB)\n",
      "     -------------------------------------- 125.0/125.0 KB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.5.0 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from prefect) (4.10.0)\n",
      "Collecting readchar<5.0.0,>=4.0.0\n",
      "  Downloading readchar-4.0.6-py3-none-any.whl (8.5 kB)\n",
      "Collecting uvicorn<0.29.0,>=0.14.0\n",
      "  Downloading uvicorn-0.28.1-py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 60.5/60.5 KB 1.6 MB/s eta 0:00:00\n",
      "Collecting coolname<3.0.0,>=1.0.4\n",
      "  Downloading coolname-2.2.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting toml>=0.10.0\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting pendulum<3.0\n",
      "  Using cached pendulum-2.1.2-cp310-cp310-win_amd64.whl\n",
      "Requirement already satisfied: cloudpickle<4.0,>=2.0 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from prefect) (3.0.0)\n",
      "Requirement already satisfied: sqlalchemy[asyncio]!=1.4.33,<3.0.0,>=1.4.22 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from prefect) (2.0.29)\n",
      "Collecting dateparser<2.0.0,>=1.1.1\n",
      "  Downloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
      "     -------------------------------------- 295.0/295.0 KB 1.2 MB/s eta 0:00:00\n",
      "Collecting typer>=0.4.2\n",
      "  Downloading typer-0.11.1-py3-none-any.whl (43 kB)\n",
      "     -------------------------------------- 43.6/43.6 KB 709.3 kB/s eta 0:00:00\n",
      "Collecting python-slugify<9.0,>=5.0\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Collecting apprise<2.0.0,>=1.1.0\n",
      "  Downloading apprise-1.7.4-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 498.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: itsdangerous in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from prefect) (2.1.2)\n",
      "Collecting orjson<4.0,>=3.7\n",
      "  Downloading orjson-3.10.0-cp310-none-win_amd64.whl (139 kB)\n",
      "     -------------------------------------- 139.2/139.2 KB 1.0 MB/s eta 0:00:00\n",
      "Collecting asyncpg>=0.23\n",
      "  Downloading asyncpg-0.29.0-cp310-cp310-win_amd64.whl (553 kB)\n",
      "     ------------------------------------ 553.1/553.1 KB 937.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging<24.3,>=21.3 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from prefect) (23.2)\n",
      "Collecting jsonpatch<2.0,>=1.32\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting python-multipart>=0.0.7\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Collecting jsonschema<5.0.0,>=3.2.0\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "     -------------------------------------- 85.5/85.5 KB 965.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz<2025,>=2021.1 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from prefect) (2024.1)\n",
      "Collecting kubernetes<30.0.0,>=24.2.0\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 890.2 kB/s eta 0:00:00\n",
      "Collecting httpcore<2.0.0,>=0.15.0\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "     -------------------------------------- 77.9/77.9 KB 393.5 kB/s eta 0:00:00\n",
      "Collecting httpx[http2]!=0.23.2,>=0.23\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "     -------------------------------------- 75.6/75.6 KB 522.8 kB/s eta 0:00:00\n",
      "Collecting griffe>=0.20.0\n",
      "  Downloading griffe-0.42.1-py3-none-any.whl (118 kB)\n",
      "     -------------------------------------- 118.5/118.5 KB 1.4 MB/s eta 0:00:00\n",
      "Collecting pathspec>=0.8.0\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: click<8.2,>=8.0 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from prefect) (8.1.7)\n",
      "Collecting pydantic[email]!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.10.0\n",
      "  Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "     ------------------------------------ 394.9/394.9 KB 947.5 kB/s eta 0:00:00\n",
      "Collecting asgi-lifespan<3.0,>=1.0\n",
      "  Downloading asgi_lifespan-2.1.0-py3-none-any.whl (10 kB)\n",
      "Collecting cryptography>=36.0.1\n",
      "  Downloading cryptography-42.0.5-cp39-abi3-win_amd64.whl (2.9 MB)\n",
      "     ---------------------------------------- 2.9/2.9 MB 768.2 kB/s eta 0:00:00\n",
      "Collecting cachetools<6.0,>=5.3\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting importlib-resources<6.2.0,>=6.1.3\n",
      "  Downloading importlib_resources-6.1.3-py3-none-any.whl (34 kB)\n",
      "Collecting ujson<6.0.0,>=5.8.0\n",
      "  Downloading ujson-5.9.0-cp310-cp310-win_amd64.whl (41 kB)\n",
      "     -------------------------------------- 41.9/41.9 KB 511.1 kB/s eta 0:00:00\n",
      "Collecting anyio<4.0.0,>=3.7.1\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "     -------------------------------------- 80.9/80.9 KB 410.8 kB/s eta 0:00:00\n",
      "Collecting ruamel.yaml>=0.17.0\n",
      "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "     ------------------------------------ 117.8/117.8 KB 768.0 kB/s eta 0:00:00\n",
      "Collecting aiosqlite>=0.17.0\n",
      "  Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.0.0 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from prefect) (3.1.3)\n",
      "Collecting docker<7.0,>=4.0\n",
      "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
      "     -------------------------------------- 148.1/148.1 KB 1.3 MB/s eta 0:00:00\n",
      "Collecting fsspec>=2022.5.0\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "     ------------------------------------ 172.0/172.0 KB 738.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from prefect) (2.9.0.post0)\n",
      "Requirement already satisfied: alembic<2.0.0,>=1.7.5 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from prefect) (1.13.1)\n",
      "Collecting graphviz>=0.20.1\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "     -------------------------------------- 47.1/47.1 KB 335.3 kB/s eta 0:00:00\n",
      "Collecting croniter<3.0.0,>=1.0.12\n",
      "  Downloading croniter-2.0.3-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.4.1 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from prefect) (6.0.1)\n",
      "Collecting sniffio<2.0.0,>=1.3.0\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: Mako in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from alembic<2.0.0,>=1.7.5->prefect) (1.3.2)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from anyio<4.0.0,>=3.7.1->prefect) (3.6)\n",
      "Requirement already satisfied: exceptiongroup in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from anyio<4.0.0,>=3.7.1->prefect) (1.2.0)\n",
      "Requirement already satisfied: certifi in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from apprise<2.0.0,>=1.1.0->prefect) (2024.2.2)\n",
      "Requirement already satisfied: markdown in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from apprise<2.0.0,>=1.1.0->prefect) (3.6)\n",
      "Collecting requests-oauthlib\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: requests in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from apprise<2.0.0,>=1.1.0->prefect) (2.31.0)\n",
      "Collecting async-timeout>=4.0.3\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: colorama in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from click<8.2,>=8.0->prefect) (0.4.6)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.16.0-cp310-cp310-win_amd64.whl (181 kB)\n",
      "     -------------------------------------- 181.6/181.6 KB 1.1 MB/s eta 0:00:00\n",
      "Collecting tzlocal\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Collecting regex!=2019.02.19,!=2021.8.27\n",
      "  Using cached regex-2023.12.25-cp310-cp310-win_amd64.whl (269 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from docker<7.0,>=4.0->prefect) (2.2.1)\n",
      "Requirement already satisfied: pywin32>=304 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from docker<7.0,>=4.0->prefect) (306)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.5/58.5 KB 1.0 MB/s eta 0:00:00\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting h2<5,>=3\n",
      "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 KB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from jinja2<4.0.0,>=3.0.0->prefect) (2.1.5)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting attrs>=22.2.0\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "     -------------------------------------- 60.8/60.8 KB 537.4 kB/s eta 0:00:00\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.18.0-cp310-none-win_amd64.whl (206 kB)\n",
      "     -------------------------------------- 206.7/206.7 KB 1.1 MB/s eta 0:00:00\n",
      "Collecting referencing>=0.28.4\n",
      "  Downloading referencing-0.34.0-py3-none-any.whl (26 kB)\n",
      "Collecting google-auth>=1.0.1\n",
      "  Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "     ------------------------------------ 189.2/189.2 KB 820.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.9.0 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from kubernetes<30.0.0,>=24.2.0->prefect) (1.16.0)\n",
      "Collecting oauthlib>=3.2.2\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting pytzdata>=2020.1\n",
      "  Downloading pytzdata-2020.1-py2.py3-none-any.whl (489 kB)\n",
      "     ------------------------------------ 490.0/490.0 KB 959.4 kB/s eta 0:00:00\n",
      "Collecting pydantic-core==2.16.3\n",
      "  Downloading pydantic_core-2.16.3-cp310-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 921.3 kB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting email-validator>=2.0.0\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.2/78.2 KB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools>=41.0 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from readchar<5.0.0,>=4.0.0->prefect) (58.1.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.5/87.5 KB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from rich<14.0,>=11.0->prefect) (2.17.2)\n",
      "Collecting ruamel.yaml.clib>=0.2.7\n",
      "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-win_amd64.whl (117 kB)\n",
      "     -------------------------------------- 117.8/117.8 KB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from sqlalchemy[asyncio]!=1.4.33,<3.0.0,>=1.4.22->prefect) (3.0.3)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting dnspython>=2.0.0\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "     ------------------------------------ 307.7/307.7 KB 826.3 kB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "     ------------------------------------ 181.2/181.2 KB 842.3 kB/s eta 0:00:00\n",
      "Collecting hyperframe<7,>=6.0\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting hpack<5,>=4.0\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from requests->apprise<2.0.0,>=1.1.0->prefect) (3.3.2)\n",
      "Requirement already satisfied: tzdata in e:\\internship_2024\\backend_data\\ml_flow\\.env\\lib\\site-packages (from tzlocal->dateparser<2.0.0,>=1.1.1->prefect) (2024.1)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "     -------------------------------------- 85.3/85.3 KB 962.5 kB/s eta 0:00:00\n",
      "Installing collected packages: text-unidecode, coolname, websockets, websocket-client, ujson, tzlocal, toml, sniffio, ruamel.yaml.clib, rpds-py, rfc3339-validator, regex, readchar, pytzdata, python-slugify, python-multipart, pydantic-core, pycparser, pyasn1, pathspec, orjson, oauthlib, mdurl, jsonpointer, importlib-resources, hyperframe, hpack, h11, griffe, graphviz, fsspec, dnspython, cachetools, attrs, async-timeout, annotated-types, aiosqlite, uvicorn, typer, ruamel.yaml, rsa, requests-oauthlib, referencing, pydantic, pyasn1-modules, pendulum, markdown-it-py, jsonpatch, httpcore, h2, email-validator, docker, dateparser, croniter, cffi, asyncpg, asgi-lifespan, anyio, rich, jsonschema-specifications, httpx, google-auth, cryptography, apprise, kubernetes, jsonschema, prefect\n",
      "  Attempting uninstall: docker\n",
      "    Found existing installation: docker 7.0.0\n",
      "    Uninstalling docker-7.0.0:\n",
      "      Successfully uninstalled docker-7.0.0\n",
      "Successfully installed aiosqlite-0.20.0 annotated-types-0.6.0 anyio-3.7.1 apprise-1.7.4 asgi-lifespan-2.1.0 async-timeout-4.0.3 asyncpg-0.29.0 attrs-23.2.0 cachetools-5.3.3 cffi-1.16.0 coolname-2.2.0 croniter-2.0.3 cryptography-42.0.5 dateparser-1.2.0 dnspython-2.6.1 docker-6.1.3 email-validator-2.1.1 fsspec-2024.3.1 google-auth-2.29.0 graphviz-0.20.3 griffe-0.42.1 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httpx-0.27.0 hyperframe-6.0.1 importlib-resources-6.1.3 jsonpatch-1.33 jsonpointer-2.4 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 kubernetes-29.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 oauthlib-3.2.2 orjson-3.10.0 pathspec-0.12.1 pendulum-2.1.2 prefect-2.16.7 pyasn1-0.6.0 pyasn1-modules-0.4.0 pycparser-2.21 pydantic-2.6.4 pydantic-core-2.16.3 python-multipart-0.0.9 python-slugify-8.0.4 pytzdata-2020.1 readchar-4.0.6 referencing-0.34.0 regex-2023.12.25 requests-oauthlib-2.0.0 rfc3339-validator-0.1.4 rich-13.7.1 rpds-py-0.18.0 rsa-4.9 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 sniffio-1.3.1 text-unidecode-1.3 toml-0.10.2 typer-0.11.1 tzlocal-5.2 ujson-5.9.0 uvicorn-0.28.1 websocket-client-1.7.0 websockets-12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'e:\\Internship_2024\\Backend_data\\ml_flow\\.env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install prefect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "@task\n",
    "def split_inputs_output(data, inputs, output):\n",
    "    \"\"\"\n",
    "    Split features and target variables.\n",
    "    \"\"\"\n",
    "    X = data[inputs]\n",
    "    y = data[output]\n",
    "    return X, y\n",
    "\t\n",
    "\n",
    "@task\n",
    "def split_train_test(X, y, test_size=0.25, random_state=0):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets.\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\t\n",
    "\t\n",
    "@task\n",
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Rescale the data.\n",
    "    \"\"\"\n",
    "    scaler = TfidfVectorizer()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\t\n",
    "\n",
    "@task\n",
    "def train_model(X_train_scaled, y_train, hyperparameters):\n",
    "    \"\"\"\n",
    "    Training the machine learning model.\n",
    "    \"\"\"\n",
    "    clf = KNeighborsClassifier(**hyperparameters)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    return clf\n",
    "\t\n",
    "\n",
    "@task\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Compute accuracy scores\n",
    "    train_score = accuracy_score(y_train, y_train_pred)\n",
    "    test_score = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    return train_score, test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@flow(name=\"KNN Training Flow\")\n",
    "def workflow():\n",
    "    DATA_PATH = r\"E:\\Internship_2024\\Backend_data\\ml_flow\\New_dataframe.csv\"\n",
    "    INPUTS = 'Review text'\n",
    "    OUTPUT = 'Ratings'\n",
    "    HYPERPARAMETERS = {'n_neighbors': 3, 'p': 2}\n",
    "    \n",
    "    # Load data\n",
    "    data = load_data(DATA_PATH)\n",
    "\n",
    "    # Identify Inputs and Output\n",
    "    X, y = split_inputs_output(data, INPUTS, OUTPUT)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = split_train_test(X, y)\n",
    "\n",
    "    # Preprocess the data\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Build a model\n",
    "    model = train_model(X_train_scaled, y_train, HYPERPARAMETERS)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_score, test_score = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    \n",
    "    print(\"Train Score:\", train_score)\n",
    "    print(\"Test Score:\", test_score)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    workflow.serve(\n",
    "        name=\"my-first-deployment\",\n",
    "        cron=\"* * * * *\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:28.767 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'KNN Training Flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:28.767 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'pink-frigatebird'\u001b[0m for flow\u001b[1;35m 'KNN Training Flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:30.380 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Created task run 'load_data-0' for task 'load_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:30.380 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Created task run 'load_data-0' for task 'load_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:30.386 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Executing 'load_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:30.386 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Executing 'load_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:40.327 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:40.327 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:40.577 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Created task run 'split_inputs_output-0' for task 'split_inputs_output'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:40.577 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Created task run 'split_inputs_output-0' for task 'split_inputs_output'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:40.581 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Executing 'split_inputs_output-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:40.581 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Executing 'split_inputs_output-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:41.274 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'split_inputs_output-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:41.274 | \u001b[36mINFO\u001b[0m    | Task run 'split_inputs_output-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:41.373 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Created task run 'split_train_test-0' for task 'split_train_test'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:41.373 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Created task run 'split_train_test-0' for task 'split_train_test'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:41.378 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Executing 'split_train_test-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:41.378 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Executing 'split_train_test-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:46.353 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'split_train_test-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:46.353 | \u001b[36mINFO\u001b[0m    | Task run 'split_train_test-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:46.492 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Created task run 'preprocess_data-0' for task 'preprocess_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:46.492 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Created task run 'preprocess_data-0' for task 'preprocess_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:46.497 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Executing 'preprocess_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:46.497 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Executing 'preprocess_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:49.131 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'preprocess_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:49.131 | \u001b[36mINFO\u001b[0m    | Task run 'preprocess_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:49.244 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Created task run 'train_model-0' for task 'train_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:49.244 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Created task run 'train_model-0' for task 'train_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:57:49.249 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Executing 'train_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:57:49.249 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Executing 'train_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/29 16:57:50 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'fb06b2d55a8b498d9c8e3af7558a60ff', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/03/29 16:57:50 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:59:15.109 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'train_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:59:15.109 | \u001b[36mINFO\u001b[0m    | Task run 'train_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:59:15.894 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Created task run 'evaluate_model-0' for task 'evaluate_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:59:15.894 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Created task run 'evaluate_model-0' for task 'evaluate_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:59:15.898 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Executing 'evaluate_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:59:15.898 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Executing 'evaluate_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:59:20.133 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'evaluate_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:59:20.133 | \u001b[36mINFO\u001b[0m    | Task run 'evaluate_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.6881855217800062\n",
      "Test Score: 0.5709586466165414\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:59:20.511 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'pink-frigatebird'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:59:20.511 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'pink-frigatebird'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
